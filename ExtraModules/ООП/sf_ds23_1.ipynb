{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7c1ac1",
   "metadata": {},
   "source": [
    "# Продвинутое программирование на языке Python\n",
    "## Семинар 1. Принципы ООП\n",
    "\n",
    "На этом занятии постараемся разобрать логику `.__init__()` -> `.fit()` -> `.transform()` (`.predict()`). Это пригодится нам при работе с `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a413ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7691ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-10, 10, (100, 2))\n",
    "y = np.random.normal(0, 1, 100)\n",
    "\n",
    "X_new = np.random.uniform(-10, 10, (50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae734db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()  # .__init__()\n",
    "# Y = b1*X1 + b2*X2 + ... + bn*Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093e3b3b-d762-40d6-acdd-12b4bf32f231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a211a8-9099-48d5-9a68-4d5e4af09084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_set_intercept',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'n_jobs',\n",
       " 'positive',\n",
       " 'predict',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6767d533-44e0-4ad8-933d-988df24fa5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a1a7a6-1890-4e89-81bc-a818a321cb68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_set_intercept',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'positive',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c57e7a-4081-444b-bc37-76ef2361ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7cf57",
   "metadata": {},
   "source": [
    "В процессе анализа данных нам часто нужно будет трансформировать их каким-либо образом. Рассмотрим две главных трансформации: стадартизацию и нормализацию.\n",
    "\n",
    "![st&norm](https://i.stack.imgur.com/XmyWR.png)\n",
    "\n",
    "Наша задача - реализовать класс `Transformer`.\n",
    "\n",
    "При этом:\n",
    "- для инициализации класса необходим вид трансформации;\n",
    "- на вход может подаваться последовательность из целых / нецелых чисел (возможные виды: `list`, `tuple`, `np.ndarray`, `pd.DataFrame`). Последовательности (если это не `np.ndarray` или `pd.DataFrame`) должны иметь степень вложенности 2 (список списков);\n",
    "- параметры для трансформации должны сохраняться в качестве атрибутов объекта (для каждой переменной);\n",
    "- должна поддерживаться логика `fit`-`transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18bc5307-d283-4f8e-9eb3-1d738c37af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    _valid_ttypes = {'st', 'norm'}\n",
    "    _valid_dtypes = {list, tuple, np.ndarray, pd.DataFrame}\n",
    "    _valid_scalar_dtypes = {'int', 'float'}  # int32, int64 etc.\n",
    "    \n",
    "    def __init__(self, ttype='st'):\n",
    "        if ttype not in self._valid_ttypes:\n",
    "            raise ValueError(f'transformation type {ttype} is not recognized, use valid types: {self._valid_ttypes}')\n",
    "\n",
    "        self.ttype = ttype\n",
    "\n",
    "    def _validate_data(self, data):\n",
    "        data_type = type(data)\n",
    "\n",
    "        # check input types\n",
    "        if data_type not in self._valid_dtypes:\n",
    "            raise ValueError(f'input data type {data_type} is not recognized, use valid dtypes: {self._valid_dtypes}')\n",
    "\n",
    "        if data_type in {list, tuple}:\n",
    "            data = np.array(data)\n",
    "        elif data_type == pd.DataFrame:\n",
    "            data = data.values\n",
    "        \n",
    "        # check dtype\n",
    "        scalar_dtype = str(data.dtype)\n",
    "        dtype_condition = any(dt in scalar_dtype for dt in self._valid_scalar_dtypes)\n",
    "        \n",
    "        if not dtype_condition:\n",
    "            raise ValueError(f'scalar data type {scalar_dtype} is not recognized, use valid types: {self._valid_scalar_dtypes}')\n",
    "\n",
    "        # check shape\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(f'invalid dimensions number {data.ndim}, must be 2')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _transform(self, data):\n",
    "        if self.ttype == 'st':\n",
    "            data_transformed = (data - self.params['mean']) / self.params['std']\n",
    "        else:\n",
    "            data_transformed = (data - self.params['min']) / (self.params['max'] - self.params['min'])\n",
    "\n",
    "        return data_transformed\n",
    "\n",
    "    def fit_transform(self, data) -> np.ndarray:\n",
    "        data_valid = self._validate_data(data)\n",
    "\n",
    "        # get params\n",
    "        if self.ttype == 'st':\n",
    "            means = data_valid.mean(axis=0)\n",
    "            stds = data_valid.std(axis=0)\n",
    "\n",
    "            self.params = {\n",
    "                'mean': means,\n",
    "                'std': stds\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            minimums = data_valid.min(axis=0)\n",
    "            maximums = data_valid.max(axis=0)\n",
    "\n",
    "            self.params = {\n",
    "                'min': minimums,\n",
    "                'max': maximums\n",
    "            }\n",
    "\n",
    "        # apply params to old data and return\n",
    "        return self._transform(data_valid) \n",
    "\n",
    "    def transform(self, new_data):\n",
    "        if not hasattr(self, 'params'):\n",
    "            raise ValueError('you cannot transform before you fit!')\n",
    "\n",
    "        # validate\n",
    "        new_data_valid = self._validate_data(new_data)\n",
    "\n",
    "        # apply params to new data and return\n",
    "        return self._transform(new_data_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6a843ce-1180-4ce4-ab90-578dcc86d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Transformer('st')\n",
    "\n",
    "X_scaled = tr.fit(X)\n",
    "X_new_scaled = tr.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80fa34-6603-42b9-b18d-8bf25a7df060",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем немного изменить логику и реализовать родительский класс Transformer и два наследуемых: StandardScaler и NormScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ab4df-85dd-4b55-babb-8f0ff1d849f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    _valid_dtypes = {list, tuple, np.ndarray, pd.DataFrame}\n",
    "    _valid_scalar_dtypes = {'int', 'float'}  # int32, int64 etc.\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _validate_data(self, data):\n",
    "        data_type = type(data)\n",
    "\n",
    "        # check input types\n",
    "        if data_type not in self._valid_dtypes:\n",
    "            raise ValueError(f'input data type {data_type} is not recognized, use valid dtypes: {self._valid_dtypes}')\n",
    "\n",
    "        if data_type in {list, tuple}:\n",
    "            data = np.array(data)\n",
    "        elif data_type == pd.DataFrame:\n",
    "            data = data.values\n",
    "        \n",
    "        # check dtype\n",
    "        scalar_dtype = str(data.dtype)\n",
    "        dtype_condition = any(dt in scalar_dtype for dt in self._valid_scalar_dtypes)\n",
    "        \n",
    "        if not dtype_condition:\n",
    "            raise ValueError(f'scalar data type {scalar_dtype} is not recognized, use valid types: {self._valid_scalar_dtypes}')\n",
    "\n",
    "        # check shape\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(f'invalid dimensions number {data.ndim}, must be 2')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _get_params(self, data):  # in future _get_params method must be here\n",
    "        pass\n",
    "\n",
    "    def _apply_params(self, data):  # in future _apply_params method must be here\n",
    "        pass\n",
    "\n",
    "    def fit(self, data) -> np.ndarray:\n",
    "        data_valid = self._validate_data(data)\n",
    "\n",
    "        # get params and save\n",
    "        self._get_params(data_valid)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if not hasattr(self, 'params'):\n",
    "            raise ValueError('you cannot transform before you fit!')\n",
    "\n",
    "        # validate\n",
    "        data_valid = self._validate_data(data)\n",
    "\n",
    "        # apply params to new data and return\n",
    "        data_transformed = self._apply_params(data_valid)\n",
    "        \n",
    "        return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fd661-935f-44e8-a90d-a50610df69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(Transformer):\n",
    "    def _get_params(self, data):  # in future _get_params method must be here\n",
    "        means = data.mean(axis=0)\n",
    "        stds = data.std(axis=0)\n",
    "\n",
    "        self.params = {\n",
    "            'mean': means,\n",
    "            'std': stds\n",
    "        }\n",
    "\n",
    "    def _apply_params(self, data):  # in future _apply_params method must be here\n",
    "        data_transformed = (data - self.params['mean']) / self.params['std']\n",
    "\n",
    "        return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5a730-a836-47e9-9ae0-b4c1f05f2371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253fbbb-1109-46d0-9257-d537cc4fb9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7c1ac1",
   "metadata": {},
   "source": [
    "# Продвинутое программирование на языке Python\n",
    "## Семинар 1. Принципы ООП\n",
    "\n",
    "На этом занятии постараемся разобрать логику `.__init__()` -> `.fit()` -> `.transform()` (`.predict()`). Это пригодится нам при работе с `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a413ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7691ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-10, 10, (100, 2))\n",
    "y = np.random.normal(0, 1, 100)\n",
    "\n",
    "X_new = np.random.uniform(-10, 10, (50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae734db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()  # .__init__()\n",
    "# Y = b0*1 + b1*X1 + b2*X2 + ... + bn*Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e533dbe4-2ed7-46e9-aa75-2da5ef6e04b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_set_intercept',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'n_jobs',\n",
       " 'positive',\n",
       " 'predict',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8fff9d-23ae-4f16-b495-24f5725bda3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f9fdf4-200a-4dda-955a-c93dd41f09e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_set_intercept',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'positive',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260fc03a-6f60-44db-a114-288d34d21820",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7cf57",
   "metadata": {},
   "source": [
    "В процессе анализа данных нам часто нужно будет трансформировать их каким-либо образом. Рассмотрим две главных трансформации: стадартизацию и нормализацию.\n",
    "\n",
    "![st&norm](https://i.stack.imgur.com/XmyWR.png)\n",
    "\n",
    "Наша задача - реализовать класс `Transformer`.\n",
    "\n",
    "При этом:\n",
    "- для инициализации класса необходим вид трансформации;\n",
    "- на вход может подаваться последовательность из целых / нецелых чисел (возможные виды: `list`, `tuple`, `np.ndarray`, `pd.DataFrame`). Последовательности (если это не `np.ndarray` или `pd.DataFrame`) должны иметь степень вложенности 2 (список списков);\n",
    "- параметры для трансформации должны сохраняться в качестве атрибутов объекта (для каждой переменной);\n",
    "- должна поддерживаться логика `fit`-`transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18bc5307-d283-4f8e-9eb3-1d738c37af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    _valid_ttypes = ['norm', 'std']\n",
    "    _valid_structures = [list, tuple, np.ndarray, pd.DataFrame]\n",
    "    _valid_dtypes = [int, float]\n",
    "    \n",
    "    def __init__(self, ttype='norm'):\n",
    "        if ttype not in self._valid_ttypes:\n",
    "            raise ValueError(f'invalid ttype {ttype}, use only authorized ttypes: {self._valid_ttypes}!')\n",
    "            \n",
    "        self.ttype = ttype\n",
    "\n",
    "    def _validate_data(self, data):\n",
    "        # check data structure\n",
    "        structure = type(data)\n",
    "        if structure not in self._valid_structures:\n",
    "            raise ValueError(f'invalid structure {structure}, use only authorized structures: {self._valid_structures}!')\n",
    "        \n",
    "        # <data> -> np.ndarray\n",
    "        if structure in [list, tuple]:\n",
    "            data = np.array(data)\n",
    "        elif structure == pd.DataFrame:\n",
    "            data = data.values\n",
    "        \n",
    "        # check dtype\n",
    "        if data.dtype not in self._valid_dtypes:\n",
    "            raise ValueError(f'invalid dtype {data.dtype}, use only authorized dtypes: {self._valid_dtypes}!')\n",
    "\n",
    "        # shape\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(f'invalid shape {data.ndim}, must be 2!')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def fit(self, data):\n",
    "        # validate data\n",
    "        data_valid = self._validate_data(data)\n",
    "        \n",
    "        # compute params\n",
    "        if self.ttype == 'norm':\n",
    "            mins = data_valid.min(axis=0)\n",
    "            maxs = data_valid.max(axis=0)\n",
    "            \n",
    "            params = {\n",
    "                'min': mins,\n",
    "                'max': maxs\n",
    "            }\n",
    "        else:\n",
    "            means = data_valid.mean(axis=0)\n",
    "            stds = data_valid.std(axis=0)\n",
    "            \n",
    "            params = {\n",
    "                'mean': means,\n",
    "                'std': stds\n",
    "            }\n",
    "            \n",
    "        # save params\n",
    "        self.params = params\n",
    "\n",
    "    def transform(self, data) -> pd.DataFrame:\n",
    "        # check if fit is applied\n",
    "        if not hasattr(self, 'params'):\n",
    "            raise AttributeError('you cannot apply transform before fit!')\n",
    "        \n",
    "        # validate data\n",
    "        data_valid = self._validate_data(data)\n",
    "\n",
    "        # apply params to data\n",
    "        if self.ttype == 'norm':\n",
    "            data_transformed = (data_valid - self.params['min']) / (self.params['max'] - self.params['min'])\n",
    "            \n",
    "        else:\n",
    "            data_transformed = (data_valid - self.params['mean']) / self.params['std']\n",
    "\n",
    "        return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d7bd3bc-0b94-40ca-ac87-7795aa12c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Transformer(ttype='std')\n",
    "tr.fit(X)\n",
    "\n",
    "X_std = tr.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d088b67f-cf84-4c93-aa3f-e02123b7be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "\n",
    "X_std = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f0db76-c18f-4af6-913e-fcf947453c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top_secret'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr._Transformer__top_secret_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86d03f2-838c-453c-b4cd-b9188f90d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f570b77f-b9bd-42b5-8e14-cb40c532c796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm', 'std']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr._valid_ttypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b6989-1535-40b9-ad71-c29063d2eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06713446-13f6-4e38-a507-498a669c6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.ttype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae56a560-13a3-4eb7-8df5-61ecf930499f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Transformer__top_secret_attribute',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_valid_ttypes',\n",
       " 'fit',\n",
       " 'transform',\n",
       " 'ttype']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80fa34-6603-42b9-b18d-8bf25a7df060",
   "metadata": {},
   "source": [
    "Теперь давайте попробуем немного изменить логику и реализовать родительский класс Transformer и два наследуемых: StandardScaler и NormScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e9ab4df-85dd-4b55-babb-8f0ff1d849f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    _valid_structures = [list, tuple, np.ndarray, pd.DataFrame]\n",
    "    _valid_dtypes = [int, float]\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _validate_data(self, data):\n",
    "        # check data structure\n",
    "        structure = type(data)\n",
    "        if structure not in self._valid_structures:\n",
    "            raise ValueError(f'invalid structure {structure}, use only authorized structures: {self._valid_structures}!')\n",
    "        \n",
    "        # <data> -> np.ndarray\n",
    "        if structure in [list, tuple]:\n",
    "            data = np.array(data)\n",
    "        elif structure == pd.DataFrame:\n",
    "            data = data.values\n",
    "        \n",
    "        # check dtype\n",
    "        if data.dtype not in self._valid_dtypes:\n",
    "            raise ValueError(f'invalid dtype {data.dtype}, use only authorized dtypes: {self._valid_dtypes}!')\n",
    "\n",
    "        # shape\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(f'invalid shape {data.ndim}, must be 2!')\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _get_params(self, data):  # must be specified in child class\n",
    "        pass\n",
    "\n",
    "    def _apply_params(self, data):  # must be specified in child class\n",
    "        pass\n",
    "\n",
    "    def fit(self, data):\n",
    "        # validate data\n",
    "        data_valid = self._validate_data(data)\n",
    "        \n",
    "        # compute params\n",
    "        params = self._get_params(data_valid)\n",
    "            \n",
    "        # save params\n",
    "        self.params = params\n",
    "\n",
    "    def transform(self, data) -> pd.DataFrame:\n",
    "        # check if fit is applied\n",
    "        if not hasattr(self, 'params'):\n",
    "            raise AttributeError('you cannot apply transform before fit!')\n",
    "        \n",
    "        # validate data\n",
    "        data_valid = self._validate_data(data)\n",
    "\n",
    "        # apply params to data\n",
    "        data_transformed = self._apply_params(data_valid)\n",
    "\n",
    "        return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7f6a5ec-1d4d-4238-8198-d7efbb621bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(Transformer):\n",
    "    def _get_params(self, data):\n",
    "        means = data.mean(axis=0)\n",
    "        stds = data.std(axis=0)\n",
    "        \n",
    "        params = {\n",
    "            'mean': means,\n",
    "            'std': stds\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def _apply_params(self, data):\n",
    "        data_transformed = (data - self.params['mean']) / self.params['std']\n",
    "\n",
    "        return data_transformed\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
